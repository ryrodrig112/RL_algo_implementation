# Hill Climbing Algorithm Implementation

### Algorithm Overview
[Hill climbing](https://en.wikipedia.org/wiki/Local_search) is an optimization method within the family of local search algorithms. As opposed to statistical machine learning methods which 
aim to minimize a cost function, hill climbing algorithms iteratively generate solutions to the problem at hand, either updating their proposed 
solution or discarding the generated solution based on its performance. 

There are [multiple approaches](https://www.geeksforgeeks.org/introduction-hill-climbing-artificial-intelligence/)
to optimization via hill climbing. This repo contains an implementation of stochastic hill climbing, where a single solution is selected from the
search space at random. If the random solution outperforms the previous best, the best solution is updated and the search space is halved in size.
If the recent solution underperforms, the search space is doubled.

### Repo Overview
**Key Files:**
* `main.py:` Will train an agent to balance a pole on a cart in the CartPole-v1 environment using the stochastic hill climbing. Training and test
records are output as csv files.
* `plots.py`: Plots performance of agent using csv files generated by `main.py`
* `hc_agent.py`: Contains class for the agent interacting with the gym environment. The hill climbing algorithm is implemented within the `update_weights` method.
* `envs.py`: Contains utility function used to generate vectorized environments.

### Constraints
As of 8/24/2022, the website certificate for the site containing documentation for the [OpenAI Gym Library](https://www.gymlibrary.ml) has expired. 
This has blocks library specific development until resolved. 

## References and Resources (In Recommended Order of Reading / Watching)
- Intro to hill climbing algorithms: [Introduction to Hill Climbing | Artificial Intelligence](https://www.geeksforgeeks.org/introduction-hill-climbing-artificial-intelligence/), [Hill Climbing Wikipedia](https://en.wikipedia.org/wiki/Hill_climbing#Variants)
- Introduction to OpenAI Gym: [Getting Started With OpenAI Gym](https://www.youtube.com/watch?v=8MC3y7ASoPs&t=44s)
- Implementing hill climbing in a single environment: [Hill Climbing Algorithm Balances a CartPole]([Hill Climbing Algorithm balances a Cart Pole](https://www.youtube.com/watch?v=WZFj81xPgyk)
- PPO example using  vectorized environmnts: [Part 1 of 3 â€” Proximal Policy Optimization Implementation: 11 Core Implementation Details](https://www.youtube.com/watch?v=MEt6rrxH8W4)
